# -*- coding: utf-8 -*-
"""Heart Disease Cleveland Finalized

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wre-yxgQkYg8Pyu8w6tyHhDkzPmY5coK

**Goals:** *Predict patient has heart disease using clinical attributes*

# **1.0 Import Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost as xgb

"""# **2.0 Load Dataset**"""

from google.colab import files
uploaded = files.upload()

"""# 2.1 Read CSV"""

df = pd.read_csv("heart_cleveland_upload.csv")

"""# 2.2 View CSV"""

df.head()

"""# **3.0 Explore Dataset (EDA)**"""

print(df.info())
print(df.describe())
print(df.isnull().sum())   # Check missing values
print(df.duplicated().sum()) # Check duplicates

"""# 3.1 Plot Target Distribution"""

sns.countplot(x='condition', data=df)
plt.title("Heart Disease Distribution (0=No, 1=Yes)")
plt.show()

"""# **4.0 Preprocessing**

# 4.1 Drop Duplicates
"""

df = df.drop_duplicates()

"""# 4.2 Encode Categorical Variables"""

categorical_cols = ['cp', 'restecg', 'slope', 'thal']
for col in categorical_cols:
    if df[col].dtype == 'object':
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])

"""# 4.3 Define Features & Condition"""

X = df.drop('condition', axis=1)
y = df['condition']

"""# 4.4 Train Test Split"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""# 4.5 Scale Features"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# **5.0 Train Models**

# 5.1 Logistic Regression
"""

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)

"""# 5.2 Random Forest"""

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

"""# 5.3 SVM"""

svm = SVC(probability=True, random_state=42)
svm.fit(X_train, y_train)

"""# 5.4 XGBoost"""

xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xg.fit(X_train, y_train)

"""# **6.0 Model Evaluation**"""

models = {'Logistic Regression': lr, 'Random Forest': rf, 'SVM': svm, 'XGBoost': xg}

for name, model in models.items():
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:,1]

    print(f"\nðŸ”¹ {name} Results:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("F1 Score:", f1_score(y_test, y_pred))
    print("ROC-AUC:", roc_auc_score(y_test, y_proba))
    print(classification_report(y_test, y_pred))

"""# **7.0 Confusion Matrices**"""

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

for ax, (name, model) in zip(axes.flatten(), models.items()):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_title(f"{name} Confusion Matrix")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

plt.tight_layout()
plt.show()

"""# **8.0 ROC Curves**"""

plt.figure(figsize=(8,6))

for name, model in models.items():
    y_proba = model.predict_proba(X_test)[:,1]
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    plt.plot(fpr, tpr, label=f"{name} (AUC={roc_auc_score(y_test, y_proba):.2f})")

plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves")
plt.legend()
plt.show()

"""# **9.0 Features Importance**"""

importances = rf.feature_importances_
features = X.columns

plt.figure(figsize=(8,6))
sns.barplot(x=importances, y=features)
plt.title("Random Forest Feature Importance")
plt.show()

xg_importances = xg.feature_importances_

plt.figure(figsize=(8,6))
sns.barplot(x=xg_importances, y=features)
plt.title("XGBoost Feature Importance")
plt.show()

"""# **10.0 Hyper Tuning**

# 10.1 Decision Tree Hyper Tuning
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

dt_params = {
    "max_depth": [3, 5, 7, None],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}
dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42),
                       param_grid=dt_params,
                       cv=5,
                       scoring="accuracy")
dt_grid.fit(X_train, y_train)

"""# 10.2 Random Forest Tuning"""

rf_params = {
    "n_estimators": [100, 200],
    "max_depth": [3, 5, 7, None],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}
rf_grid = GridSearchCV(RandomForestClassifier(random_state=42),
                       param_grid=rf_params,
                       cv=5,
                       scoring="accuracy",
                       n_jobs=-1)
rf_grid.fit(X_train, y_train)

"""# **11.0 Tuned Model Evaluation**"""

from sklearn.model_selection import cross_val_score

tuned_models = {
    "Tuned Decision Tree": dt_grid.best_estimator_,
    "Tuned Random Forest": rf_grid.best_estimator_
}

results = {} # Initialize results dictionary

for name, model in tuned_models.items():
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    train_acc = accuracy_score(y_train, y_train_pred)
    test_acc = accuracy_score(y_test, y_test_pred)
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)

    results[name] = {
        "Train Accuracy": round(train_acc, 4),
        "Test Accuracy": round(test_acc, 4),
        "CV Mean Accuracy": round(np.mean(cv_scores), 4),
        "CV Std Dev": round(np.std(cv_scores), 4)
    }

    print(f"\n{name} - Best Params: {model.get_params()}")

"""# **12.0 Comparison**"""

print("\n=== Final Model Comparison ===")
comparison_df = pd.DataFrame(results).T
print(comparison_df)

"""# **13.0 Test with New Input**"""

# Example new patient input (values must match dataset features order)
# The features are: age, sex, cp, trestbps, chol, fbs, restecg,
# thalach, exang, oldpeak, slope, ca, thal

new_data = {
    "age": [55],
    "sex": [1],         # 1 = male, 0 = female
    "cp": [2],          # chest pain type (encoded)
    "trestbps": [140],  # resting blood pressure
    "chol": [250],      # serum cholesterol
    "fbs": [0],         # fasting blood sugar > 120 mg/dl
    "restecg": [1],     # resting ECG results
    "thalach": [160],   # maximum heart rate achieved
    "exang": [0],       # exercise induced angina
    "oldpeak": [1.2],   # ST depression
    "slope": [2],       # slope of ST segment
    "ca": [0],          # number of major vessels colored
    "thal": [2]         # thalassemia (encoded)
}

"""# **13.1 Convert to DataFrame**"""

new_df = pd.DataFrame(new_data)

"""# **13.2 Feature Scaling**"""

new_df_scaled = scaler.transform(new_df)

"""# **13.3 Model Prediction**"""

print("\n=== Prediction on New Patient Data ===")
for name, model in models.items():
    pred = model.predict(new_df_scaled)[0]
    proba = model.predict_proba(new_df_scaled)[0][1]
    print(f"{name}: Predicted = {pred} (Probability of Heart Disease = {proba:.2f})")